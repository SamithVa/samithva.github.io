{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"SeeClick\"\n",
        "author: \"Samith Va\"\n",
        "date: \"2024-08-20\"\n",
        "categories: [LVLMs]\n",
        "format:\n",
        "    html:\n",
        "        toc: true \n",
        "        code-fold: true\n",
        "        code-summary: \"Show the code\"\n",
        "---\n",
        "\n",
        "\n",
        "**SeeClick** is a visual based GUI agent which is built on top of Qwen-VL-Chat. Using this agent, you can interact with the eletronics device in more efficient way, in other word it is a smarter agent (compare with Siri, Alexa, Google Assistant).  \n",
        "\n",
        "# Model Architecture\n",
        "\n",
        "How SeeClick is built? There are mainly 2 steps in forming SeeClick.\n",
        "\n",
        "1. GUI-Grouding : Use many GUI datasets^[train with 1 millions dataset, contained 30 different task] to improve model understanding in the world of widgets such as [RICO](http://www.interactionmining.org/rico.html)\n",
        "\n",
        "2. Fine-tuning : Fine-tune with goal-oriented instruction.\n",
        "\n",
        "In simple words, There are two stages of finetuning, and each stage is finetuned with different dataset.\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "  A[Qwen-VL-Chat-Int4] -->|Widget Caption Dataset| B[Qwen Checkpoint]\n",
        "  B --> |AITW Dataset| C[SeeClick]\n",
        "```\n",
        "\n",
        "\n",
        "Due to limited resources, I only able to train the GUI-Grouding stage with only one small dataset ^[RICO, Widget Captioning] on 4 RX4090 GPUs with 24GB RAM each. Using q-LORA for the fine-tuning stage, it takes about 3 hours. Below is the training configuration :\n",
        "\n",
        "\n",
        "```{bash}\n",
        "torchrun $DISTRIBUTED_ARGS qwen_finetune.py \\\n",
        "    --model_name_or_path $MODEL \\\n",
        "    --data_path $DATA \\\n",
        "    --fp16 True \\\n",
        "    --fix_vit True \\\n",
        "    --output_dir output_qwen \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 1000 \\\n",
        "    --save_total_limit 10 \\\n",
        "    --learning_rate 1e-5 \\\n",
        "    --weight_decay 0.1 \\\n",
        "    --adam_beta2 0.95 \\\n",
        "    --warmup_ratio 0.01 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --report_to \"none\" \\\n",
        "    --model_max_length 512 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --use_lora \\\n",
        "    --q_lora \\\n",
        "    --gradient_checkpointing \\\n",
        "    --deepspeed finetune/ds_config_zero2.json\n",
        "\n",
        "```"
      ],
      "id": "bd257fff"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}